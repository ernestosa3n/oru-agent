# Deployment Notes â€” Oru Hedera Agent

This document describes how the Oru agent would be deployed in a real environment.  
For the hackathon version, the deployment remains conceptual and focuses on demonstrating a production-oriented architecture.

---

## Containerized Deployment

The Oru agent is designed to run as a containerized service.

A real deployment would include:

- Python runtime  
- Oru source code (`/src`)  
- all dependencies from `requirements.txt`  
- environment variables for configuration  

Example Docker build command (conceptual):

```bash
docker build -t oru-hedera-agent .
```

Example run command:

```bash
docker run \
  -e HEDERA_MIRROR_NODE_URL="https://testnet.mirrornode.hedera.com" \
  -e HEDERA_NETWORK="testnet" \
  oru-hedera-agent
```

---

## Scheduling & Execution

The intelligence loop could be triggered via:

- a cron job running inside the container  
- an external scheduler (e.g., Kubernetes CronJob)  
- manual or API-triggered execution  
- a cloud-based task runner  

Each loop cycle would produce a new insight and update the memory layer.

---

## Output Delivery

Insights generated by the agent may be delivered through:

- JSON logs (for future pipelines)  
- local or cloud storage (S3, IPFS, etc.)  
- an internal API endpoint  
- an external dashboard (conceptualized in Figma)  
- alerts via webhook, email, or messaging apps  

For the hackathon, output is demonstrated conceptually through:

- the formatted insight object  
- the Figma dashboard  
- the documentation

---

## Scaling Model (Future)

A scalable deployment could include:

- container orchestration (Kubernetes)  
- horizontal scaling for ingestion-heavy workloads  
- distributed memory or database backends  
- event-driven execution using Hedera triggers or cloud functions  

These notes establish a credible path to real production deployment without requiring full implementation during the hackathon.
